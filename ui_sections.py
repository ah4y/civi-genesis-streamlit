"""
UI sections for CIVI-GENESIS Streamlit app.
Modular functions for rendering different parts of the interface.
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from typing import List, Dict, Any, Optional
from data_models import (
    Citizen, CitizenState, SimulationConfig, StepStats,
    PolicyInput, DOMAINS, SIMULATION_MODES
)
from utils import format_support, format_income, get_policy_presets


def render_sidebar_controls() -> Optional[SimulationConfig]:
    """
    Render sidebar controls for simulation configuration.
    
    Returns:
        SimulationConfig object if user clicks run, None otherwise.
    """
    st.sidebar.title("‚öôÔ∏è Simulation Controls")
    
    # Population settings
    st.sidebar.subheader("Population")
    population_size = st.sidebar.slider(
        "Population Size",
        min_value=100,
        max_value=50000,
        value=1000,
        step=100,
        help="Number of synthetic citizens to simulate"
    )
    
    # Income distribution
    with st.sidebar.expander("Income Distribution", expanded=False):
        low_share = st.slider("Low Income %", 0, 100, 40) / 100
        middle_share = st.slider("Middle Income %", 0, 100, 40) / 100
        high_share = 1.0 - low_share - middle_share
        st.write(f"High Income: {high_share * 100:.0f}%")
    
    # Simulation steps
    steps = st.sidebar.slider(
        "Simulation Steps",
        min_value=1,
        max_value=10,
        value=5,
        help="Number of time steps to simulate"
    )
    
    # Simulation mode
    st.sidebar.subheader("Learning Mode")
    mode = st.sidebar.selectbox(
        "Select Mode",
        options=SIMULATION_MODES,
        index=0,
        help="""
        - LLM_ONLY: Use LLM for sampled citizens, rule-based for others
        - HYBRID: Use LLM for samples + NN for rest (when trained)
        - NN_ONLY: Use NN for all (when trained), else rule-based
        """
    )
    
    # Random seed
    use_seed = st.sidebar.checkbox("Use Random Seed", value=False)
    random_seed = None
    if use_seed:
        random_seed = st.sidebar.number_input("Seed", value=42, min_value=0)
    
    # Policy configuration
    st.sidebar.subheader("Policy Configuration")
    
    # Policy presets
    presets = get_policy_presets()
    preset_names = ["Custom"] + [p["title"] for p in presets]
    selected_preset = st.sidebar.selectbox("Policy Preset", preset_names)
    
    if selected_preset != "Custom":
        preset = next(p for p in presets if p["title"] == selected_preset)
        policy_title = st.sidebar.text_input("Policy Title", value=preset["title"])
        policy_description = st.sidebar.text_area(
            "Policy Description",
            value=preset["description"],
            height=100
        )
        policy_domain = st.sidebar.selectbox(
            "Policy Domain",
            options=DOMAINS,
            index=DOMAINS.index(preset["domain"])
        )
    else:
        policy_title = st.sidebar.text_input("Policy Title", value="")
        policy_description = st.sidebar.text_area(
            "Policy Description",
            value="",
            height=100
        )
        policy_domain = st.sidebar.selectbox("Policy Domain", options=DOMAINS)
    
    # Scenario name
    scenario_name = st.sidebar.text_input(
        "Scenario Name",
        value=f"{policy_title[:20] if policy_title else 'Unnamed'} - {mode}",
        help="Name for this simulation run"
    )
    
    # Run button
    run_simulation = st.sidebar.button("üöÄ Run Simulation", type="primary", use_container_width=True)
    
    if run_simulation and policy_title and policy_description:
        config = SimulationConfig(
            name=scenario_name,
            population_size=population_size,
            steps=steps,
            policy=PolicyInput(
                title=policy_title,
                description=policy_description,
                domain=policy_domain
            ),
            random_seed=random_seed,
            mode=mode
        )
        return config
    
    return None


def render_learning_status_panel(
    num_samples: int,
    model_trained: bool,
    current_mode: str
):
    """
    Render the learning status panel showing NN training progress.
    
    Args:
        num_samples: Number of LLM-labeled samples collected.
        model_trained: Whether the NN model is trained.
        current_mode: Current simulation mode.
    """
    st.subheader("üß† Hybrid AI Learning Status")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "LLM Samples Collected",
            f"{num_samples:,}",
            help="Number of citizen reactions generated by LLM for training"
        )
    
    with col2:
        status_emoji = "‚úÖ" if model_trained else "‚ùå"
        status_text = "Trained" if model_trained else "Not Trained"
        st.metric(
            "Neural Network",
            f"{status_emoji} {status_text}",
            help="Whether the NN model has been trained on LLM samples"
        )
    
    with col3:
        st.metric(
            "Current Mode",
            current_mode,
            help="Current simulation mode being used"
        )
    
    # Progress towards training
    if not model_trained and num_samples > 0:
        min_samples = 500
        progress = min(num_samples / min_samples, 1.0)
        st.progress(progress)
        st.caption(f"Need {min_samples} samples to train NN. Current: {num_samples}")


def render_overview_tab(step_stats: List[StepStats], current_step: int):
    """
    Render the overview tab with time-series charts and key metrics.
    
    Args:
        step_stats: List of StepStats for all simulation steps.
        current_step: Currently selected step for detailed view.
    """
    st.subheader("üìä Simulation Overview")
    
    if not step_stats:
        st.info("No simulation data available. Run a simulation to see results.")
        return
    
    # Create time series dataframe
    df = pd.DataFrame([
        {
            "Step": s.step,
            "Avg Happiness": s.avg_happiness,
            "Avg Support": s.avg_support,
            "Avg Income": s.avg_income
        }
        for s in step_stats
    ])
    
    # Time series charts
    col1, col2 = st.columns(2)
    
    with col1:
        # Happiness over time
        fig_happiness = px.line(
            df,
            x="Step",
            y="Avg Happiness",
            title="Average Happiness Over Time",
            markers=True
        )
        fig_happiness.update_layout(yaxis_range=[0, 1])
        st.plotly_chart(fig_happiness, use_container_width=True)
    
    with col2:
        # Support over time
        fig_support = px.line(
            df,
            x="Step",
            y="Avg Support",
            title="Average Policy Support Over Time",
            markers=True
        )
        fig_support.update_layout(yaxis_range=[-1, 1])
        st.plotly_chart(fig_support, use_container_width=True)
    
    # Income over time
    fig_income = px.line(
        df,
        x="Step",
        y="Avg Income",
        title="Average Income Over Time",
        markers=True
    )
    st.plotly_chart(fig_income, use_container_width=True)
    
    # Key metrics for selected step
    st.subheader(f"Key Metrics - Step {current_step}")
    current_stats = step_stats[current_step] if current_step < len(step_stats) else step_stats[-1]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Avg Happiness", f"{current_stats.avg_happiness:.2f}")
    
    with col2:
        st.metric("Avg Support", format_support(current_stats.avg_support))
    
    with col3:
        st.metric("Avg Income", format_income(current_stats.avg_income))
    
    with col4:
        st.metric("Happiness Gap", f"{current_stats.inequality_gap_happiness:.3f}")


def render_groups_tab(step_stats: List[StepStats], current_step: int):
    """
    Render the groups tab with breakdowns by income and city zone.
    
    Args:
        step_stats: List of StepStats for all simulation steps.
        current_step: Currently selected step.
    """
    st.subheader("üë• Group Analysis")
    
    if not step_stats or current_step >= len(step_stats):
        st.info("No data available for this step.")
        return
    
    current_stats = step_stats[current_step]
    
    # By income level
    st.subheader(f"By Income Level - Step {current_step}")
    
    if current_stats.by_income:
        income_df = pd.DataFrame(current_stats.by_income)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_income_happ = px.bar(
                income_df,
                x="income_level",
                y="avg_happiness",
                title="Happiness by Income Level",
                color="income_level",
                labels={"income_level": "Income Level", "avg_happiness": "Avg Happiness"}
            )
            fig_income_happ.update_layout(yaxis_range=[0, 1], showlegend=False)
            st.plotly_chart(fig_income_happ, use_container_width=True)
        
        with col2:
            fig_income_supp = px.bar(
                income_df,
                x="income_level",
                y="avg_support",
                title="Support by Income Level",
                color="income_level",
                labels={"income_level": "Income Level", "avg_support": "Avg Support"}
            )
            fig_income_supp.update_layout(yaxis_range=[-1, 1], showlegend=False)
            st.plotly_chart(fig_income_supp, use_container_width=True)
    
    # By city zone
    st.subheader(f"By City Zone - Step {current_step}")
    
    if current_stats.by_zone:
        zone_df = pd.DataFrame(current_stats.by_zone)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_zone_happ = px.bar(
                zone_df,
                x="city_zone",
                y="avg_happiness",
                title="Happiness by City Zone",
                color="city_zone",
                labels={"city_zone": "City Zone", "avg_happiness": "Avg Happiness"}
            )
            fig_zone_happ.update_layout(yaxis_range=[0, 1], showlegend=False)
            st.plotly_chart(fig_zone_happ, use_container_width=True)
        
        with col2:
            fig_zone_supp = px.bar(
                zone_df,
                x="city_zone",
                y="avg_support",
                title="Support by City Zone",
                color="city_zone",
                labels={"city_zone": "City Zone", "avg_support": "Avg Support"}
            )
            fig_zone_supp.update_layout(yaxis_range=[-1, 1], showlegend=False)
            st.plotly_chart(fig_zone_supp, use_container_width=True)
    
    # Inequality metrics
    st.subheader("Inequality Metrics")
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric(
            "Happiness Gap (High - Low Income)",
            f"{current_stats.inequality_gap_happiness:.3f}",
            help="Difference in average happiness between high and low income groups"
        )
    
    with col2:
        st.metric(
            "Support Gap (High - Low Income)",
            f"{current_stats.inequality_gap_support:.3f}",
            help="Difference in average support between high and low income groups"
        )


def render_citizens_tab(
    citizens: List[Citizen],
    all_states: List[CitizenState],
    current_step: int
):
    """
    Render the citizens tab with individual citizen browser.
    
    Args:
        citizens: List of all citizens.
        all_states: List of all citizen states.
        current_step: Currently selected step.
    """
    st.subheader("üë§ Citizen Browser")
    
    if not citizens or not all_states:
        st.info("No citizen data available.")
        return
    
    # Get states for current step
    states_at_step = [s for s in all_states if s.step == current_step]
    
    # Create citizen map
    citizen_map = {c.id: c for c in citizens}
    
    # Build dataframe for display
    citizen_rows = []
    for state in states_at_step[:100]:  # Limit to first 100 for performance
        citizen = citizen_map.get(state.citizen_id)
        if citizen:
            citizen_rows.append({
                "ID": citizen.id,
                "Age": citizen.age,
                "Profession": citizen.profession,
                "Income Level": citizen.income_level,
                "City Zone": citizen.city_zone,
                "Happiness": f"{state.happiness:.2f}",
                "Support": format_support(state.policy_support),
                "Income": format_income(state.income),
                "Has Diary": "‚úÖ" if state.diary_entry else "‚ùå",
                "LLM Updated": "‚úÖ" if state.llm_updated else "‚ùå"
            })
    
    if not citizen_rows:
        st.info("No citizens to display.")
        return
    
    citizen_df = pd.DataFrame(citizen_rows)
    
    # Filters
    col1, col2 = st.columns(2)
    
    with col1:
        income_filter = st.multiselect(
            "Filter by Income Level",
            options=["low", "middle", "high"],
            default=["low", "middle", "high"]
        )
    
    with col2:
        zone_filter = st.multiselect(
            "Filter by City Zone",
            options=["downtown", "industrial", "suburban", "rural"],
            default=["downtown", "industrial", "suburban", "rural"]
        )
    
    # Apply filters
    filtered_df = citizen_df[
        citizen_df["Income Level"].isin(income_filter) &
        citizen_df["City Zone"].isin(zone_filter)
    ]
    
    # Display table
    st.dataframe(filtered_df, use_container_width=True, height=400)
    
    # Citizen detail view
    st.subheader("Citizen Detail View")
    
    citizen_id = st.number_input(
        "Enter Citizen ID to view details",
        min_value=0,
        max_value=len(citizens) - 1,
        value=0
    )
    
    if citizen_id < len(citizens):
        render_citizen_detail(citizen_id, citizens, all_states)


def render_citizen_detail(
    citizen_id: int,
    citizens: List[Citizen],
    all_states: List[CitizenState]
):
    """
    Render detailed view for a specific citizen.
    
    Args:
        citizen_id: ID of the citizen to display.
        citizens: List of all citizens.
        all_states: List of all citizen states.
    """
    citizen = next((c for c in citizens if c.id == citizen_id), None)
    
    if not citizen:
        st.error(f"Citizen {citizen_id} not found.")
        return
    
    # Citizen profile
    st.write("**Profile**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write(f"**Age:** {citizen.age}")
        st.write(f"**Gender:** {citizen.gender}")
        st.write(f"**Profession:** {citizen.profession}")
    
    with col2:
        st.write(f"**Income Level:** {citizen.income_level}")
        st.write(f"**Education:** {citizen.education}")
        st.write(f"**City Zone:** {citizen.city_zone}")
    
    with col3:
        st.write(f"**Political View:** {citizen.political_view}")
        st.write(f"**Risk Tolerance:** {citizen.risk_tolerance:.2f}")
        st.write(f"**Openness:** {citizen.openness_to_change:.2f}")
    
    # Get all states for this citizen
    citizen_states = [s for s in all_states if s.citizen_id == citizen_id]
    citizen_states.sort(key=lambda s: s.step)
    
    if not citizen_states:
        st.info("No state data for this citizen.")
        return
    
    # Time series for this citizen
    citizen_df = pd.DataFrame([
        {
            "Step": s.step,
            "Happiness": s.happiness,
            "Support": s.policy_support,
            "Income": s.income
        }
        for s in citizen_states
    ])
    
    st.write("**Timeline**")
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.line(citizen_df, x="Step", y="Happiness", markers=True, title="Happiness")
        fig.update_layout(yaxis_range=[0, 1])
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.line(citizen_df, x="Step", y="Support", markers=True, title="Support")
        fig.update_layout(yaxis_range=[-1, 1])
        st.plotly_chart(fig, use_container_width=True)
    
    # Diary entries
    st.write("**Diary Entries**")
    diary_states = [s for s in citizen_states if s.diary_entry]
    
    if diary_states:
        for state in diary_states:
            with st.expander(f"Step {state.step}"):
                st.write(state.diary_entry)
    else:
        st.info("No diary entries for this citizen.")


def render_experts_tab(expert_summary: Optional[Dict[str, str]]):
    """
    Render the experts tab with AI-generated summaries.
    
    Args:
        expert_summary: Dict with economist_view, activist_view, business_owner_view.
    """
    st.subheader("üéì Expert Perspectives")
    
    if not expert_summary:
        st.info("No expert summary available. Run a simulation first.")
        return
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üíº Economist")
        st.write(expert_summary.get("economist_view", "No view available."))
    
    with col2:
        st.markdown("### ‚úä Social Activist")
        st.write(expert_summary.get("activist_view", "No view available."))
    
    with col3:
        st.markdown("### üè™ Business Owner")
        st.write(expert_summary.get("business_owner_view", "No view available."))


def render_scenarios_tab(scenarios: Dict[str, Any]):
    """
    Render the scenarios tab for comparing multiple simulation runs.
    
    Args:
        scenarios: Dict of scenario_name -> scenario_data.
    """
    st.subheader("üìÇ Scenario Management")
    
    if not scenarios:
        st.info("No scenarios available. Run simulations to create scenarios.")
        return
    
    st.write(f"**Total Scenarios:** {len(scenarios)}")
    
    # List scenarios
    scenario_rows = []
    for name, data in scenarios.items():
        config = data["config"]
        scenario_rows.append({
            "Name": name,
            "Mode": config.mode,
            "Population": config.population_size,
            "Steps": config.steps,
            "Policy": config.policy.title
        })
    
    scenario_df = pd.DataFrame(scenario_rows)
    st.dataframe(scenario_df, use_container_width=True)
    
    # Scenario comparison
    if len(scenarios) >= 2:
        st.subheader("Compare Scenarios")
        
        scenario_names = list(scenarios.keys())
        col1, col2 = st.columns(2)
        
        with col1:
            scenario_a_name = st.selectbox("Scenario A", scenario_names, index=0)
        
        with col2:
            scenario_b_name = st.selectbox("Scenario B", scenario_names, index=1)
        
        if scenario_a_name != scenario_b_name:
            render_scenario_comparison(
                scenarios[scenario_a_name],
                scenarios[scenario_b_name],
                scenario_a_name,
                scenario_b_name
            )


def render_scenario_comparison(
    scenario_a: Dict[str, Any],
    scenario_b: Dict[str, Any],
    name_a: str,
    name_b: str
):
    """
    Render side-by-side comparison of two scenarios.
    
    Args:
        scenario_a: First scenario data.
        scenario_b: Second scenario data.
        name_a: Name of first scenario.
        name_b: Name of second scenario.
    """
    st.subheader(f"Comparison: {name_a} vs {name_b}")
    
    # Create comparison dataframes
    stats_a = scenario_a["step_stats"]
    stats_b = scenario_b["step_stats"]
    
    df_a = pd.DataFrame([
        {"Step": s.step, "Happiness": s.avg_happiness, "Support": s.avg_support, "Scenario": name_a}
        for s in stats_a
    ])
    
    df_b = pd.DataFrame([
        {"Step": s.step, "Happiness": s.avg_happiness, "Support": s.avg_support, "Scenario": name_b}
        for s in stats_b
    ])
    
    df_combined = pd.concat([df_a, df_b])
    
    # Comparison charts
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.line(
            df_combined,
            x="Step",
            y="Happiness",
            color="Scenario",
            markers=True,
            title="Happiness Comparison"
        )
        fig.update_layout(yaxis_range=[0, 1])
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.line(
            df_combined,
            x="Step",
            y="Support",
            color="Scenario",
            markers=True,
            title="Support Comparison"
        )
        fig.update_layout(yaxis_range=[-1, 1])
        st.plotly_chart(fig, use_container_width=True)


def render_nn_analytics_tab(nn_model, nn_stats, training_samples, mode):
    """
    Render Neural Network Analytics and Performance Metrics.
    
    Args:
        nn_model: Trained neural network model
        nn_stats: Statistics from simulation about NN usage
        training_samples: Total number of training samples
        mode: Simulation mode used
    """
    import streamlit as st
    import plotly.graph_objects as go
    import numpy as np
    
    st.header('üß† Neural Network Analytics')
    
    if nn_model is None:
        st.warning('No NN model trained yet. Run a simulation first to collect training data.')
        return
    
    # Training Information
    st.subheader('üìä Training Information')
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric('Training Samples', f'{training_samples:,}')
    with col2:
        if hasattr(nn_model, 'train_mae_'):
            st.metric('Train MAE', f'{nn_model.train_mae_:.4f}')
        else:
            st.metric('Train MAE', 'N/A')
    with col3:
        if hasattr(nn_model, 'val_mae_'):
            st.metric('Val MAE', f'{nn_model.val_mae_:.4f}')
        else:
            st.metric('Val MAE', 'N/A')
    with col4:
        st.metric('Training Status', '‚úÖ Ready' if nn_model else '‚ùå Not Trained')
    
    if not nn_stats:
        st.info('Run a simulation to see NN performance statistics.')
        return
    
    # Current Simulation Performance
    st.subheader('‚ö° Current Simulation Performance')
    total_llm = nn_stats.get('total_llm_calls', 0)
    total_nn = nn_stats.get('total_nn_predictions', 0)
    total_rule = nn_stats.get('total_rule_based', 0)
    total_decisions = total_llm + total_nn + total_rule
    
    col1, col2, col3 = st.columns(3)
    with col1:
        llm_pct = (total_llm / total_decisions * 100) if total_decisions > 0 else 0
        st.metric('LLM Calls', f'{total_llm:,}', f'{llm_pct:.1f}%')
    with col2:
        nn_pct = (total_nn / total_decisions * 100) if total_decisions > 0 else 0
        st.metric('NN Predictions', f'{total_nn:,}', f'{nn_pct:.1f}%')
    with col3:
        rule_pct = (total_rule / total_decisions * 100) if total_decisions > 0 else 0
        st.metric('Rule-Based', f'{total_rule:,}', f'{rule_pct:.1f}%')
    
    # Speed & Efficiency Metrics
    st.subheader('üöÄ Speed & Efficiency')
    nn_times = nn_stats.get('nn_prediction_times', [])
    if nn_times:
        avg_nn_time_ms = np.mean(nn_times) * 1000
        predictions_per_sec = 1000 / avg_nn_time_ms if avg_nn_time_ms > 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric('Avg NN Time', f'{avg_nn_time_ms:.2f} ms')
        with col2:
            st.metric('Throughput', f'{predictions_per_sec:.0f}/sec')
        with col3:
            # Estimate: LLM takes ~500ms per call, NN takes ~0.5ms
            est_llm_time = 0.5  # 500ms
            time_saved = (total_nn * est_llm_time) - (total_nn * avg_nn_time_ms / 1000)
            st.metric('Time Saved', f'{time_saved:.1f}s')
        with col4:
            speedup = est_llm_time / (avg_nn_time_ms / 1000) if avg_nn_time_ms > 0 else 0
            st.metric('Speedup vs LLM', f'{speedup:.0f}x')
    
    # Cost Savings (approximate)
    st.subheader('üí∞ Cost Savings')
    cost_per_llm_call = 0.0001  # Example: $0.0001 per call
    llm_cost = total_llm * cost_per_llm_call
    saved_cost = total_nn * cost_per_llm_call  # What would have been spent
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric('LLM Cost', f'${llm_cost:.4f}')
    with col2:
        st.metric('Cost Saved (NN)', f'${saved_cost:.4f}')
    with col3:
        total_possible_cost = (total_llm + total_nn) * cost_per_llm_call
        savings_pct = (saved_cost / total_possible_cost * 100) if total_possible_cost > 0 else 0
        st.metric('Savings %', f'{savings_pct:.1f}%')
    
    # Step-by-Step Breakdown
    st.subheader('üìà Step-by-Step Breakdown')
    step_breakdown = nn_stats.get('step_breakdown', [])
    if step_breakdown:
        # Create stacked bar chart
        steps = list(range(1, len(step_breakdown) + 1))
        llm_counts = [s['llm_calls'] for s in step_breakdown]
        nn_counts = [s['nn_predictions'] for s in step_breakdown]
        rule_counts = [s['rule_based'] for s in step_breakdown]
        
        fig = go.Figure(data=[
            go.Bar(name='LLM Calls', x=steps, y=llm_counts, marker_color='#FF6B6B'),
            go.Bar(name='NN Predictions', x=steps, y=nn_counts, marker_color='#4ECDC4'),
            go.Bar(name='Rule-Based', x=steps, y=rule_counts, marker_color='#95E1D3')
        ])
        
        fig.update_layout(
            barmode='stack',
            title='Decision Types per Simulation Step',
            xaxis_title='Step',
            yaxis_title='Count',
            height=400,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Model Comparison
    st.subheader('‚öñÔ∏è Model Comparison')
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('**ü§ñ LLM Advantages:**')
        st.markdown('''
        - Rich, contextual understanding
        - Generates natural language explanations
        - Handles novel situations
        - Nuanced reasoning
        ''')
        
    with col2:
        st.markdown('**üß† Neural Network Advantages:**')
        st.markdown('''
        - 100-1000x faster predictions
        - No API costs
        - Consistent predictions
        - Scales to millions of decisions
        ''')
    
    # Optimization Recommendations
    st.subheader('üí° Optimization Recommendations')
    if mode == 'LLM_ONLY':
        st.info('''
        **Current Mode: LLM_ONLY**  
        This mode collects high-quality training data. After collecting 1000+ samples,  
        switch to HYBRID mode to leverage both LLM quality and NN speed.
        ''')
    elif mode == 'HYBRID':
        if total_llm > total_nn:
            st.warning('''
            **Current Mode: HYBRID**  
            LLM calls exceed NN predictions. Consider increasing the NN prediction ratio  
            in the simulation settings for better performance.
            ''')
        else:
            st.success('''
            **Current Mode: HYBRID**  
            Good balance between LLM quality and NN speed. Monitor the NN validation MAE  
            to ensure prediction accuracy remains acceptable.
            ''')
    elif mode == 'NN_ONLY':
        st.success('''
        **Current Mode: NN_ONLY**  
        Maximum speed and efficiency. Periodically collect new LLM samples to retrain  
        and improve NN predictions as the simulation evolves.
        ''')
    
    # Detailed Metrics Explanation
    with st.expander('üìñ Metrics Explanation'):
        st.markdown('''
        **Training Metrics:**
        - **Training Samples**: Number of LLM-generated reactions used to train the NN
        - **Train MAE**: Mean Absolute Error on training data (lower is better)
        - **Val MAE**: Mean Absolute Error on validation data (measures generalization)
        
        **Performance Metrics:**
        - **LLM Calls**: Direct calls to the language model (high quality, slower)
        - **NN Predictions**: Neural network predictions (fast, scales well)
        - **Rule-Based**: Simple heuristic updates (fastest, limited applicability)
        
        **Speed Metrics:**
        - **Avg NN Time**: Average time per NN prediction in milliseconds
        - **Throughput**: Number of predictions the NN can make per second
        - **Time Saved**: Estimated time saved by using NN vs LLM for those predictions
        - **Speedup vs LLM**: How many times faster NN is compared to LLM calls
        
        **Cost Metrics:**
        - **LLM Cost**: Estimated cost of actual LLM API calls made
        - **Cost Saved**: Estimated cost saved by using NN instead of LLM
        - **Savings %**: Percentage of potential costs saved through NN usage
        ''')
